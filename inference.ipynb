{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ad6afed",
   "metadata": {},
   "source": [
    "# Import dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7ca647c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install ai-edge-litert qai_hub_models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "109c9918",
   "metadata": {},
   "outputs": [],
   "source": [
    "from qai_hub_models.models.facemap_3dmm.model import MODEL_ASSET_VERSION, MODEL_ID\n",
    "from qai_hub_models.utils.asset_loaders import CachedWebModelAsset\n",
    "from ai_edge_litert.interpreter import Interpreter\n",
    "import os, cv2, numpy as np\n",
    "from pathlib import Path\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c995007",
   "metadata": {},
   "source": [
    "# Initialize Assets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4c7fcf6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'meanFace.npy': 'assets/meanFace.npy', 'shapeBasis.npy': 'assets/shapeBasis.npy', 'blendShape.npy': 'assets/blendShape.npy', 'face_img.jpg': 'assets/face_img.jpg', 'face_img_fbox.txt': 'assets/face_img_fbox.txt'}\n"
     ]
    }
   ],
   "source": [
    "ASSET_NAMES = [\n",
    "    \"meanFace.npy\",\n",
    "    \"shapeBasis.npy\",\n",
    "    \"blendShape.npy\",\n",
    "    \"face_img.jpg\",\n",
    "    \"face_img_fbox.txt\",\n",
    "]\n",
    "\n",
    "out_dir = Path(\"./assets\")\n",
    "out_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "resolved = {}\n",
    "for name in ASSET_NAMES:\n",
    "    src_path = CachedWebModelAsset.from_asset_store(\n",
    "        MODEL_ID, MODEL_ASSET_VERSION, name\n",
    "    ).fetch()\n",
    "    dst_path = out_dir / name\n",
    "    shutil.copy2(src_path, dst_path)\n",
    "    resolved[name] = str(dst_path)\n",
    "\n",
    "print(resolved)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "495415cb",
   "metadata": {},
   "source": [
    "# Import utility functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "610ea73e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ASSETS_DIR = \"./assets\"\n",
    "\n",
    "\n",
    "def _load_assets(assets_dir=ASSETS_DIR):\n",
    "    face = np.load(Path(assets_dir) / \"meanFace.npy\").reshape(-1, 1).astype(np.float32)\n",
    "    basis_id = np.load(Path(assets_dir) / \"shapeBasis.npy\").astype(np.float32)\n",
    "    basis_exp = np.load(Path(assets_dir) / \"blendShape.npy\").astype(np.float32)\n",
    "    vn = 68\n",
    "    face = face.reshape(3 * vn, 1)\n",
    "    basis_id = basis_id.reshape(3 * vn, 219)\n",
    "    basis_exp = basis_exp.reshape(3 * vn, 39)\n",
    "    return face, basis_id, basis_exp, vn\n",
    "\n",
    "\n",
    "def _project(output, face, basis_id, basis_exp, vn):\n",
    "    a_id = output[0:219]\n",
    "    a_exp = output[219:258]\n",
    "    pitch = output[258]\n",
    "    yaw = output[259]\n",
    "    roll = output[260]\n",
    "    tX = output[261]\n",
    "    tY = output[262]\n",
    "    f = output[263]\n",
    "    a_id = a_id * 3.0\n",
    "    a_exp = a_exp * 0.5 + 0.5\n",
    "    pitch = pitch * np.pi / 2.0\n",
    "    yaw = yaw * np.pi / 2.0\n",
    "    roll = roll * np.pi / 2.0\n",
    "    tX = tX * 60.0\n",
    "    tY = tY * 60.0\n",
    "    tZ = 500.0\n",
    "    f = f * 150.0 + 450.0\n",
    "    p = np.array(\n",
    "        [\n",
    "            [1.0, 0.0, 0.0],\n",
    "            [0.0, np.cos(-np.pi), -np.sin(-np.pi)],\n",
    "            [0.0, np.sin(-np.pi), np.cos(-np.pi)],\n",
    "        ],\n",
    "        dtype=np.float32,\n",
    "    )\n",
    "    cr, sr = np.cos(-roll), np.sin(-roll)\n",
    "    cp, sp = np.cos(-pitch), np.sin(-pitch)\n",
    "    cy, sy = np.cos(-yaw), np.sin(-yaw)\n",
    "    Rz = np.array([[cr, -sr, 0.0], [sr, cr, 0.0], [0.0, 0.0, 1.0]], dtype=np.float32)\n",
    "    Ry = np.array([[cy, 0.0, sy], [0.0, 1.0, 0.0], [-sy, 0.0, cy]], dtype=np.float32)\n",
    "    Rx = np.array([[1.0, 0.0, 0.0], [0.0, cp, -sp], [0.0, sp, cp]], dtype=np.float32)\n",
    "    R = Ry @ (Rx @ (p @ Rz))\n",
    "    shape = face + basis_id @ a_id.reshape(-1, 1) + basis_exp @ a_exp.reshape(-1, 1)\n",
    "    shape = shape.reshape(vn, 3)\n",
    "    V = shape @ R.T\n",
    "    V[:, 0] += tX\n",
    "    V[:, 1] += tY\n",
    "    V[:, 2] += tZ\n",
    "    lm = V[:, :2] * (f / tZ)\n",
    "    return lm.astype(np.float32), float(pitch), float(yaw), float(roll)\n",
    "\n",
    "\n",
    "def _normalize(inp, mode):\n",
    "    if mode == \"0_1\":\n",
    "        return inp.astype(np.float32) / 255.0\n",
    "    if mode == \"neg1_1\":\n",
    "        return (inp.astype(np.float32) / 127.5) - 1.0\n",
    "    return inp.astype(np.float32)\n",
    "\n",
    "\n",
    "def _rect_to_square(x0, y0, x1, y1, H, W, scale=1.1):\n",
    "    cx = 0.5 * (x0 + x1)\n",
    "    cy = 0.5 * (y0 + y1)\n",
    "    side = max(x1 - x0 + 1, y1 - y0 + 1) * scale\n",
    "    nx0 = int(round(cx - side / 2))\n",
    "    ny0 = int(round(cy - side / 2))\n",
    "    nx1 = int(round(cx + side / 2))\n",
    "    ny1 = int(round(cy + side / 2))\n",
    "    nx0 = max(0, nx0)\n",
    "    ny0 = max(0, ny0)\n",
    "    nx1 = min(W - 1, nx1)\n",
    "    ny1 = min(H - 1, ny1)\n",
    "    return nx0, ny0, nx1, ny1\n",
    "\n",
    "\n",
    "def _prep(\n",
    "    img,\n",
    "    bbox,\n",
    "    ih,\n",
    "    iw,\n",
    "    bbox_order=\"x0y0x1y1\",\n",
    "    square_crop=True,\n",
    "    square_scale=1.1,\n",
    "    norm=\"0_1\",\n",
    "    to_rgb=True,\n",
    "):\n",
    "    H, W = img.shape[:2]\n",
    "    if bbox is None:\n",
    "        x0, y0, x1, y1 = 0, 0, W - 1, H - 1\n",
    "    else:\n",
    "        if bbox_order == \"x0x1y0y1\":\n",
    "            x0, x1, y0, y1 = bbox\n",
    "            x0, y0, x1, y1 = int(x0), int(y0), int(x1), int(y1)\n",
    "        else:\n",
    "            x0, y0, x1, y1 = [int(v) for v in bbox]\n",
    "    if square_crop:\n",
    "        x0, y0, x1, y1 = _rect_to_square(x0, y0, x1, y1, H, W, square_scale)\n",
    "    roi = img[y0 : y1 + 1, x0 : x1 + 1]\n",
    "    if to_rgb:\n",
    "        roi = cv2.cvtColor(roi, cv2.COLOR_BGR2RGB)\n",
    "    roi = cv2.resize(roi, (iw, ih), interpolation=cv2.INTER_LINEAR)\n",
    "    inp = _normalize(roi, norm)[np.newaxis, ...]\n",
    "    return inp, (x0, y0, x1, y1)\n",
    "\n",
    "\n",
    "def _transform(lm, bbox, rh, rw):\n",
    "    x0, y0, x1, y1 = bbox\n",
    "    h = (y1 - y0) + 1\n",
    "    w = (x1 - x0) + 1\n",
    "    out = lm.copy()\n",
    "    out[:, 0] = (out[:, 0] + rw / 2.0) * (w / rw) + x0\n",
    "    out[:, 1] = (out[:, 1] + rh / 2.0) * (h / rh) + y0\n",
    "    return out\n",
    "\n",
    "\n",
    "def annotate_image(\n",
    "    image_path,\n",
    "    interpreter,\n",
    "    assets_dir=ASSETS_DIR,\n",
    "    bbox=None,\n",
    "    save_path=None,\n",
    "    bbox_order=\"x0y0x1y1\",\n",
    "    square_crop=True,\n",
    "    square_scale=1.1,\n",
    "    norm=\"0_1\",\n",
    "    to_rgb=True,\n",
    "    radius=10,\n",
    "    thickness=-1,\n",
    "):\n",
    "    face, basis_id, basis_exp, vn = _load_assets(assets_dir)\n",
    "    inp_info = interpreter.get_input_details()[0]\n",
    "    out_info = interpreter.get_output_details()[0]\n",
    "    ih, iw = int(inp_info[\"shape\"][1]), int(inp_info[\"shape\"][2])\n",
    "    img = cv2.imread(image_path)\n",
    "    inp, bbox_xyxy = _prep(\n",
    "        img, bbox, ih, iw, bbox_order, square_crop, square_scale, norm, to_rgb\n",
    "    )\n",
    "    interpreter.set_tensor(inp_info[\"index\"], inp.astype(np.float32))\n",
    "    interpreter.invoke()\n",
    "    out = interpreter.get_tensor(out_info[\"index\"])[0]\n",
    "    lm_crop, pitch, yaw, roll = _project(out, face, basis_id, basis_exp, vn)\n",
    "    lm_img = _transform(lm_crop, bbox_xyxy, ih, iw)\n",
    "    vis = img.copy()\n",
    "    for x, y in lm_img:\n",
    "        cv2.circle(vis, (int(round(x)), int(round(y))), radius, (0, 255, 0), thickness)\n",
    "    deg = np.array([pitch, yaw, roll]) * (180.0 / np.pi)\n",
    "    cv2.putText(\n",
    "        vis,\n",
    "        f\"pitch:{deg[0]:.1f} yaw:{deg[1]:.1f} roll:{deg[2]:.1f}\",\n",
    "        (bbox_xyxy[0], max(0, bbox_xyxy[1] - 10)),\n",
    "        cv2.FONT_HERSHEY_SIMPLEX,\n",
    "        0.55,\n",
    "        (0, 255, 0),\n",
    "        1,\n",
    "        cv2.LINE_AA,\n",
    "    )\n",
    "    if save_path:\n",
    "        Path(save_path).parent.mkdir(parents=True, exist_ok=True)\n",
    "        cv2.imwrite(save_path, vis)\n",
    "    return lm_img, {\n",
    "        \"pitch_rad\": pitch,\n",
    "        \"yaw_rad\": yaw,\n",
    "        \"roll_rad\": roll,\n",
    "        \"pitch_deg\": deg[0],\n",
    "        \"yaw_deg\": deg[1],\n",
    "        \"roll_deg\": deg[2],\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "94098ae4",
   "metadata": {},
   "source": [
    "# Initialize TFLite Interpreter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c2ede8d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Model loaded and tensors allocated successfully.\n",
      "\n",
      "--- Model Details ---\n",
      "Inputs:\n",
      " {'name': 'image', 'index': 0, 'shape': array([  1, 128, 128,   3], dtype=int32), 'shape_signature': array([  1, 128, 128,   3], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "Outputs:\n",
      " {'name': 'parameters_3dmm', 'index': 85, 'shape': array([  1, 265], dtype=int32), 'shape_signature': array([  1, 265], dtype=int32), 'dtype': <class 'numpy.float32'>, 'quantization': (0.0, 0), 'quantization_parameters': {'scales': array([], dtype=float32), 'zero_points': array([], dtype=int32), 'quantized_dimension': 0}, 'sparsity_parameters': {}}\n",
      "---------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "MODEL_PATH = \"./facemap_3dmm-facial-landmark-detection-float.tflite\"\n",
    "SAMPLE_DIR = \"./sample\"\n",
    "RESULTS_DIR = \"./results\"\n",
    "CONF_THRESH = 0.5\n",
    "NUM_LANDMARKS = 68\n",
    "\n",
    "os.makedirs(RESULTS_DIR, exist_ok=True)\n",
    "\n",
    "try:\n",
    "    interpreter = Interpreter(model_path=MODEL_PATH)\n",
    "    interpreter.allocate_tensors()\n",
    "    print(\"✅ Model loaded and tensors allocated successfully.\")\n",
    "except Exception as e:\n",
    "    print(f\"❌ Error loading model: {e}\")\n",
    "    print(\"Please ensure the model file is at the correct path:\", MODEL_PATH)\n",
    "    exit()\n",
    "\n",
    "input_details = interpreter.get_input_details()[0]\n",
    "output_details = interpreter.get_output_details()[0]\n",
    "\n",
    "INPUT_SHAPE = input_details[\"shape\"]\n",
    "INPUT_HEIGHT = INPUT_SHAPE[1]\n",
    "INPUT_WIDTH = INPUT_SHAPE[2]\n",
    "\n",
    "print(\"\\n--- Model Details ---\")\n",
    "print(\"Inputs:\\n\", input_details)\n",
    "print(\"Outputs:\\n\", output_details)\n",
    "print(\"---------------------\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "469c17c8",
   "metadata": {},
   "source": [
    "# Fetch image files from sample directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ca08a57d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔄Loading sample images...\n",
      "✅Sample Images Loaded\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    print(\"🔄Loading sample images...\")\n",
    "    image_files = [f for f in os.listdir(SAMPLE_DIR) if f.endswith(\".jpg\")]\n",
    "    if not image_files:\n",
    "        print(\"⚠️ No .jpg images found in the 'sample' directory.\")\n",
    "except FileNotFoundError:\n",
    "    print(f\"❌ Error: The directory '{SAMPLE_DIR}' was not found.\")\n",
    "    image_files = []\n",
    "finally:\n",
    "    print(\"✅Sample Images Loaded\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18fa56bb",
   "metadata": {},
   "source": [
    "# Run inference on each sample image (.jpg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "560e7282",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yaw-left.jpg {'pitch_rad': 0.05, 'yaw_rad': -0.72, 'roll_rad': 0.03, 'pitch_deg': 2.76, 'yaw_deg': -41.2, 'roll_deg': 1.76}\n",
      "pitch-up.jpg {'pitch_rad': 0.49, 'yaw_rad': -0.03, 'roll_rad': -0.02, 'pitch_deg': 28.28, 'yaw_deg': -1.81, 'roll_deg': -1.32}\n",
      "roll-left.jpg {'pitch_rad': -0.04, 'yaw_rad': -0.01, 'roll_rad': -0.37, 'pitch_deg': -2.03, 'yaw_deg': -0.42, 'roll_deg': -21.45}\n",
      "roll-right.jpg {'pitch_rad': -0.11, 'yaw_rad': 0.03, 'roll_rad': 0.46, 'pitch_deg': -6.24, 'yaw_deg': 1.82, 'roll_deg': 26.16}\n",
      "yaw-right.jpg {'pitch_rad': 0.17, 'yaw_rad': 0.75, 'roll_rad': 0.03, 'pitch_deg': 9.85, 'yaw_deg': 42.98, 'roll_deg': 1.69}\n",
      "pitch-down.jpg {'pitch_rad': -0.64, 'yaw_rad': 0.02, 'roll_rad': -0.02, 'pitch_deg': -36.88, 'yaw_deg': 1.24, 'roll_deg': -1.32}\n"
     ]
    }
   ],
   "source": [
    "paths = [p for p in Path(SAMPLE_DIR).glob(\"*.jpg\")]\n",
    "for p in paths:\n",
    "    out_path = str(Path(RESULTS_DIR) / (p.stem + \"_annotated.jpg\"))\n",
    "    lmk, pose = annotate_image(\n",
    "        str(p), interpreter, assets_dir=ASSETS_DIR, bbox=None, save_path=out_path\n",
    "    )\n",
    "    print(\n",
    "        p.name,\n",
    "        {\n",
    "            k: round(v, 2) if isinstance(v, float) else round(float(v), 2)\n",
    "            for k, v in pose.items()\n",
    "        },\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "bbcb0955",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[126.83038, 197.18317],\n",
       "        [126.00188, 232.7856 ],\n",
       "        [128.54886, 265.7019 ],\n",
       "        [134.95789, 303.11304],\n",
       "        [146.1018 , 327.98413],\n",
       "        [159.56046, 346.99725],\n",
       "        [176.70488, 361.6625 ],\n",
       "        [196.4616 , 374.26166],\n",
       "        [216.79756, 379.0856 ],\n",
       "        [237.49966, 377.42395],\n",
       "        [258.77606, 367.99692],\n",
       "        [277.66913, 356.1018 ],\n",
       "        [293.50354, 339.33038],\n",
       "        [308.1042 , 316.3846 ],\n",
       "        [319.86957, 280.38083],\n",
       "        [327.32095, 248.21677],\n",
       "        [331.89447, 212.90955],\n",
       "        [159.67911, 188.68365],\n",
       "        [169.63725, 186.15634],\n",
       "        [180.50061, 185.62088],\n",
       "        [192.06578, 187.00038],\n",
       "        [201.97835, 190.01627],\n",
       "        [258.63364, 195.50662],\n",
       "        [268.67697, 194.55695],\n",
       "        [280.21143, 195.40579],\n",
       "        [290.87762, 197.74857],\n",
       "        [300.47906, 201.62383],\n",
       "        [229.38187, 208.47101],\n",
       "        [227.98453, 227.60217],\n",
       "        [226.4234 , 248.89262],\n",
       "        [225.12665, 265.03357],\n",
       "        [200.04495, 276.2463 ],\n",
       "        [208.68648, 277.91125],\n",
       "        [223.6472 , 281.28177],\n",
       "        [238.85779, 280.50015],\n",
       "        [247.557  , 280.20703],\n",
       "        [165.75728, 206.36081],\n",
       "        [179.20517, 199.868  ],\n",
       "        [190.95477, 201.86049],\n",
       "        [200.74274, 211.88432],\n",
       "        [189.3645 , 214.59637],\n",
       "        [178.25409, 213.89275],\n",
       "        [256.87155, 216.2528 ],\n",
       "        [268.03693, 208.3077 ],\n",
       "        [279.91425, 208.24408],\n",
       "        [292.24982, 216.1981 ],\n",
       "        [278.77582, 221.67122],\n",
       "        [267.71054, 220.65228],\n",
       "        [180.67868, 303.9654 ],\n",
       "        [192.87363, 300.2881 ],\n",
       "        [212.57483, 301.63422],\n",
       "        [221.71927, 304.0045 ],\n",
       "        [231.01276, 303.23004],\n",
       "        [250.50156, 305.12064],\n",
       "        [262.34558, 310.79816],\n",
       "        [249.69907, 323.41486],\n",
       "        [231.25655, 327.01096],\n",
       "        [220.41887, 326.31735],\n",
       "        [209.55931, 325.26337],\n",
       "        [191.66591, 318.70334],\n",
       "        [182.26108, 303.92892],\n",
       "        [210.40091, 309.73303],\n",
       "        [221.10388, 311.25262],\n",
       "        [231.81506, 311.55206],\n",
       "        [260.8781 , 310.49042],\n",
       "        [231.79272, 312.94363],\n",
       "        [221.47015, 312.5697 ],\n",
       "        [211.17065, 311.25552]], dtype=float32),\n",
       " {'pitch_rad': -0.09138459519805629,\n",
       "  'yaw_rad': -0.0028255443466920797,\n",
       "  'roll_rad': 0.07652824078269146,\n",
       "  'pitch_deg': -5.235951617360115,\n",
       "  'yaw_deg': -0.16189176589250565,\n",
       "  'roll_deg': 4.384745210409164})"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "fbox = np.loadtxt(\"./assets/face_img_fbox.txt\")\n",
    "x0, x1, y0, y1 = [int(v) for v in fbox]\n",
    "bbox = (x0, y0, x1, y1)\n",
    "annotate_image(\n",
    "    \"./assets/face_img.jpg\",\n",
    "    interpreter,\n",
    "    bbox=bbox,\n",
    "    save_path=\"./results/qcom_demo_check.jpg\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
